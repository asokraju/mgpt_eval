{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Embedding Computation (No Padding)\n",
    "\n",
    "This notebook demonstrates how to generate embeddings **one at a time without padding** using the `/embeddings` endpoint.\n",
    "\n",
    "## Key Differences from Batch Processing\n",
    "- ‚úÖ **No Padding**: Each claim processed at its natural length\n",
    "- ‚úÖ **Single Sample**: One claim per API request\n",
    "- ‚úÖ **Different Endpoint**: Uses `/embeddings` instead of `/embeddings_batch`\n",
    "- ‚ö†Ô∏è **Slower**: More API calls but no padding overhead\n",
    "\n",
    "## When to Use This Approach\n",
    "- When you need exact embeddings without padding artifacts\n",
    "- For small datasets where speed isn't critical\n",
    "- When analyzing how padding affects embeddings\n",
    "- For debugging or understanding individual claim processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from models.config_models import PipelineConfig\n",
    "\n",
    "print(\"‚úÖ Imports successful\")\n",
    "print(f\"üìÅ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Configuration and Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_file = \"configs/embedding_example_config.yaml\"\n",
    "with open(config_file, 'r') as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "# Create PipelineConfig object\n",
    "config = PipelineConfig(**config_data)\n",
    "\n",
    "# Load sample data\n",
    "data_file = config.resolve_template_string(config.input.dataset_path)\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üìã Columns: {list(df.columns)}\")\n",
    "print(f\"üè∑Ô∏è  Label distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# For demonstration, let's use a smaller subset\n",
    "sample_size = min(10, len(df))  # Process only 10 samples for demo\n",
    "df_sample = df.head(sample_size).copy()\n",
    "print(f\"\\nüìå Using {sample_size} samples for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compare Claim Lengths\n",
    "\n",
    "Let's examine the natural lengths of our claims to understand the impact of no padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate claim lengths\n",
    "df_sample['claim_length'] = df_sample['claims'].str.len()\n",
    "df_sample['word_count'] = df_sample['claims'].str.split().str.len()\n",
    "\n",
    "print(\"üìè Claim Length Statistics:\")\n",
    "print(f\"  Character count: {df_sample['claim_length'].min()} - {df_sample['claim_length'].max()} (avg: {df_sample['claim_length'].mean():.0f})\")\n",
    "print(f\"  Word count: {df_sample['word_count'].min()} - {df_sample['word_count'].max()} (avg: {df_sample['word_count'].mean():.0f})\")\n",
    "\n",
    "print(\"\\nüìù Sample claims with lengths:\")\n",
    "for idx, row in df_sample.iterrows():\n",
    "    print(f\"\\n{idx+1}. [Length: {row['claim_length']}, Words: {row['word_count']}]\")\n",
    "    print(f\"   {row['claims'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Configure Single Embedding API\n",
    "\n",
    "We'll set up the single embedding endpoint (no batching, no padding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration for single embeddings\n",
    "api_base_url = config.model_api.base_url\n",
    "single_embedding_endpoint = f\"{api_base_url}/embeddings\"  # Note: /embeddings not /embeddings_batch\n",
    "\n",
    "print(f\"üåê API Configuration:\")\n",
    "print(f\"  Base URL: {api_base_url}\")\n",
    "print(f\"  Single Embedding Endpoint: {single_embedding_endpoint}\")\n",
    "print(f\"  Batch Endpoint (for comparison): {api_base_url}{config.model_api.endpoints['embeddings_batch']}\")\n",
    "\n",
    "# Test single embedding endpoint\n",
    "test_claim = \"Regular exercise improves cardiovascular health\"\n",
    "test_payload = {\n",
    "    \"claim\": test_claim  # Note: 'claim' not 'claims' for single endpoint\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(single_embedding_endpoint, json=test_payload, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    \n",
    "    embedding = result.get('embedding', [])\n",
    "    if embedding:\n",
    "        print(f\"\\n‚úÖ Single embedding API test successful\")\n",
    "        print(f\"üìè Embedding dimension: {len(embedding)}\")\n",
    "        print(f\"üî¢ Sample values (first 5): {embedding[:5]}\")\n",
    "    else:\n",
    "        print(f\"‚ùå No embedding returned. Response: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Single embedding API test failed: {e}\")\n",
    "    print(f\"Make sure the API supports single embedding endpoint at {single_embedding_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Single Embeddings (No Padding)\n",
    "\n",
    "Process each claim individually without any padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_embedding(claim, endpoint, max_retries=3):\n",
    "    \"\"\"Generate embedding for a single claim without padding.\"\"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"claim\": claim  # Single claim, no padding parameters\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(endpoint, json=payload, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            embedding = result.get('embedding')\n",
    "            if not embedding:\n",
    "                raise ValueError(f\"No embedding in response: {result}\")\n",
    "                \n",
    "            return embedding\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise RuntimeError(f\"Failed after {max_retries} attempts: {e}\")\n",
    "            time.sleep(1 * (attempt + 1))  # Exponential backoff\n",
    "\n",
    "# Generate embeddings one by one\n",
    "print(\"üöÄ Generating single embeddings (no padding)...\\n\")\n",
    "\n",
    "embeddings = []\n",
    "processing_times = []\n",
    "\n",
    "for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=\"Processing claims\"):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        embedding = generate_single_embedding(row['claims'], single_embedding_endpoint)\n",
    "        embeddings.append(embedding)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        processing_times.append(processing_time)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error processing claim {idx}: {e}\")\n",
    "        embeddings.append(None)\n",
    "        processing_times.append(None)\n",
    "\n",
    "# Summary statistics\n",
    "successful = sum(1 for e in embeddings if e is not None)\n",
    "avg_time = np.mean([t for t in processing_times if t is not None])\n",
    "\n",
    "print(f\"\\n‚úÖ Embedding generation complete!\")\n",
    "print(f\"üìä Success rate: {successful}/{len(df_sample)} ({successful/len(df_sample)*100:.1f}%)\")\n",
    "print(f\"‚è±Ô∏è  Average processing time per claim: {avg_time:.3f} seconds\")\n",
    "print(f\"‚è±Ô∏è  Total processing time: {sum(t for t in processing_times if t is not None):.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Compare with Batch Processing (With Padding)\n",
    "\n",
    "Let's generate embeddings using the batch endpoint with padding for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batch embeddings with padding for comparison\n",
    "batch_endpoint = f\"{api_base_url}{config.model_api.endpoints['embeddings_batch']}\"\n",
    "\n",
    "print(\"üöÄ Generating batch embeddings (with padding) for comparison...\\n\")\n",
    "\n",
    "# Prepare batch request with padding parameters\n",
    "batch_payload = {\n",
    "    \"claims\": df_sample['claims'].tolist(),\n",
    "    \"padding_side\": config.embedding_generation.padding_side,\n",
    "    \"truncation_side\": config.embedding_generation.truncation_side,\n",
    "    \"max_length\": config.embedding_generation.max_sequence_length\n",
    "}\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    response = requests.post(batch_endpoint, json=batch_payload, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    \n",
    "    batch_embeddings = result.get('embeddings', [])\n",
    "    batch_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Batch processing complete!\")\n",
    "    print(f\"üìä Generated {len(batch_embeddings)} embeddings\")\n",
    "    print(f\"‚è±Ô∏è  Total batch processing time: {batch_time:.3f} seconds\")\n",
    "    print(f\"‚ö° Speedup: {sum(t for t in processing_times if t is not None) / batch_time:.1f}x faster\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Batch processing failed: {e}\")\n",
    "    batch_embeddings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Analyze Differences\n",
    "\n",
    "Compare embeddings generated with and without padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare embeddings if both methods succeeded\n",
    "if embeddings and batch_embeddings and all(e is not None for e in embeddings[:len(batch_embeddings)]):\n",
    "    \n",
    "    print(\"üìä Comparing Single vs Batch Embeddings:\\n\")\n",
    "    \n",
    "    # Calculate differences\n",
    "    differences = []\n",
    "    for i, (single_emb, batch_emb) in enumerate(zip(embeddings, batch_embeddings)):\n",
    "        if single_emb is not None:\n",
    "            single_array = np.array(single_emb)\n",
    "            batch_array = np.array(batch_emb)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            cosine_sim = np.dot(single_array, batch_array) / (np.linalg.norm(single_array) * np.linalg.norm(batch_array))\n",
    "            l2_distance = np.linalg.norm(single_array - batch_array)\n",
    "            max_diff = np.max(np.abs(single_array - batch_array))\n",
    "            \n",
    "            differences.append({\n",
    "                'claim_length': df_sample.iloc[i]['claim_length'],\n",
    "                'cosine_similarity': cosine_sim,\n",
    "                'l2_distance': l2_distance,\n",
    "                'max_difference': max_diff\n",
    "            })\n",
    "    \n",
    "    # Display results\n",
    "    diff_df = pd.DataFrame(differences)\n",
    "    \n",
    "    print(\"üìà Similarity Statistics:\")\n",
    "    print(f\"  Cosine Similarity: {diff_df['cosine_similarity'].mean():.6f} (¬±{diff_df['cosine_similarity'].std():.6f})\")\n",
    "    print(f\"  L2 Distance: {diff_df['l2_distance'].mean():.6f} (¬±{diff_df['l2_distance'].std():.6f})\")\n",
    "    print(f\"  Max Element Difference: {diff_df['max_difference'].mean():.6f} (¬±{diff_df['max_difference'].std():.6f})\")\n",
    "    \n",
    "    print(\"\\nüìä Per-Sample Comparison:\")\n",
    "    display_df = diff_df.copy()\n",
    "    display_df.index = [f\"Claim {i+1}\" for i in range(len(display_df))]\n",
    "    print(display_df.round(6))\n",
    "    \n",
    "    # Correlation with claim length\n",
    "    if len(diff_df) > 3:\n",
    "        length_corr = diff_df['claim_length'].corr(diff_df['l2_distance'])\n",
    "        print(f\"\\nüìè Correlation between claim length and L2 distance: {length_corr:.3f}\")\n",
    "        \n",
    "        if abs(length_corr) > 0.3:\n",
    "            print(\"   ‚Üí Padding appears to have length-dependent effects on embeddings\")\n",
    "        else:\n",
    "            print(\"   ‚Üí Padding effects appear relatively consistent across claim lengths\")\n",
    "            \n",
    "else:\n",
    "    print(\"‚ùå Could not compare embeddings - one or both methods failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Embedding Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'diff_df' in locals() and len(diff_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # 1. Cosine similarity distribution\n",
    "    axes[0, 0].hist(diff_df['cosine_similarity'], bins=10, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 0].set_title('Cosine Similarity Distribution\\n(Single vs Batch Embeddings)')\n",
    "    axes[0, 0].set_xlabel('Cosine Similarity')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].axvline(diff_df['cosine_similarity'].mean(), color='red', linestyle='--', label=f\"Mean: {diff_df['cosine_similarity'].mean():.4f}\")\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. L2 distance vs claim length\n",
    "    axes[0, 1].scatter(diff_df['claim_length'], diff_df['l2_distance'], alpha=0.6, s=50)\n",
    "    axes[0, 1].set_title('L2 Distance vs Claim Length')\n",
    "    axes[0, 1].set_xlabel('Claim Length (characters)')\n",
    "    axes[0, 1].set_ylabel('L2 Distance')\n",
    "    \n",
    "    # Add trend line if enough points\n",
    "    if len(diff_df) > 3:\n",
    "        z = np.polyfit(diff_df['claim_length'], diff_df['l2_distance'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[0, 1].plot(diff_df['claim_length'], p(diff_df['claim_length']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # 3. Processing time comparison\n",
    "    single_time = sum(t for t in processing_times if t is not None)\n",
    "    batch_time_value = batch_time if 'batch_time' in locals() else 0\n",
    "    \n",
    "    axes[1, 0].bar(['Single\\n(No Padding)', 'Batch\\n(With Padding)'], \n",
    "                   [single_time, batch_time_value],\n",
    "                   color=['orange', 'green'], alpha=0.7)\n",
    "    axes[1, 0].set_title('Processing Time Comparison')\n",
    "    axes[1, 0].set_ylabel('Time (seconds)')\n",
    "    \n",
    "    # Add speedup annotation\n",
    "    if batch_time_value > 0:\n",
    "        speedup = single_time / batch_time_value\n",
    "        axes[1, 0].text(0.5, max(single_time, batch_time_value) * 0.8, \n",
    "                       f'Batch is {speedup:.1f}x faster', \n",
    "                       ha='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 4. Element-wise difference heatmap (for first embedding)\n",
    "    if embeddings[0] is not None and batch_embeddings:\n",
    "        diff_vector = np.abs(np.array(embeddings[0]) - np.array(batch_embeddings[0]))\n",
    "        # Reshape for visualization (create a 2D view)\n",
    "        plot_size = int(np.sqrt(len(diff_vector)))\n",
    "        if plot_size ** 2 <= len(diff_vector):\n",
    "            diff_matrix = diff_vector[:plot_size**2].reshape(plot_size, plot_size)\n",
    "            im = axes[1, 1].imshow(diff_matrix, cmap='hot', aspect='auto')\n",
    "            axes[1, 1].set_title(f'Element-wise Differences (First {plot_size}¬≤={plot_size**2} dims)')\n",
    "            axes[1, 1].set_xlabel('Dimension')\n",
    "            axes[1, 1].set_ylabel('Dimension')\n",
    "            plt.colorbar(im, ax=axes[1, 1])\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'Embedding dimension\\nnot suitable for\\nsquare visualization', \n",
    "                           ha='center', va='center', fontsize=12)\n",
    "            axes[1, 1].set_xlim(0, 1)\n",
    "            axes[1, 1].set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/single_vs_batch_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüíæ Comparison plots saved to 'outputs/single_vs_batch_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the single embeddings (no padding)\n",
    "if embeddings and any(e is not None for e in embeddings):\n",
    "    # Prepare output directory\n",
    "    output_dir = Path(config.resolve_template_string(config.output.embeddings_dir))\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create output dataframe\n",
    "    output_data = []\n",
    "    for i, (idx, row) in enumerate(df_sample.iterrows()):\n",
    "        if embeddings[i] is not None:\n",
    "            output_data.append({\n",
    "                'mcid': row['mcid'],\n",
    "                'label': row['label'],\n",
    "                'embedding': json.dumps(embeddings[i])\n",
    "            })\n",
    "    \n",
    "    output_df = pd.DataFrame(output_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = output_dir / \"single_embeddings_no_padding.csv\"\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Single embeddings saved to: {output_file}\")\n",
    "    print(f\"üìä Saved {len(output_df)} embeddings\")\n",
    "    \n",
    "    # Also save comparison results if available\n",
    "    if 'diff_df' in locals():\n",
    "        comparison_file = output_dir / \"padding_comparison_results.csv\"\n",
    "        diff_df.to_csv(comparison_file, index=False)\n",
    "        print(f\"üìä Comparison results saved to: {comparison_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### üéØ Key Findings\n",
    "\n",
    "1. **Processing Method Differences**:\n",
    "   - **Single (No Padding)**: Each claim processed at natural length\n",
    "   - **Batch (With Padding)**: All claims padded to same length for efficiency\n",
    "\n",
    "2. **Performance Trade-offs**:\n",
    "   - **Speed**: Batch processing is significantly faster (typically 5-10x)\n",
    "   - **Accuracy**: Single processing may be more accurate for varying-length inputs\n",
    "   - **Memory**: Single processing uses less memory (no padding overhead)\n",
    "\n",
    "3. **Embedding Differences**:\n",
    "   - Embeddings are generally very similar (high cosine similarity)\n",
    "   - Differences may correlate with claim length\n",
    "   - Padding can introduce subtle artifacts in the embeddings\n",
    "\n",
    "### üìù Recommendations\n",
    "\n",
    "**Use Single Embeddings (No Padding) when**:\n",
    "- Processing small datasets\n",
    "- Need exact embeddings without padding artifacts  \n",
    "- Analyzing embedding quality or debugging\n",
    "- Claim lengths vary significantly\n",
    "\n",
    "**Use Batch Embeddings (With Padding) when**:\n",
    "- Processing large datasets\n",
    "- Speed is critical\n",
    "- Claim lengths are relatively uniform\n",
    "- Small embedding differences are acceptable\n",
    "\n",
    "### üîß Configuration Notes\n",
    "\n",
    "To switch between methods in your pipeline:\n",
    "- **Single**: Use endpoint `/embeddings` with payload `{\"claim\": \"...\"}`\n",
    "- **Batch**: Use endpoint `/embeddings_batch` with padding parameters\n",
    "\n",
    "The choice depends on your specific use case and requirements!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}