{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Complete Configuration Guide\n",
    "\n",
    "## Overview\n",
    "\n",
    "This guide covers all configuration options for the MGPT-Eval pipeline. Understanding these settings will help you optimize the pipeline for your specific use case, data size, and computational resources.\n",
    "\n",
    "## üìÅ Configuration File Structure\n",
    "\n",
    "All configuration files use YAML format with this structure:\n",
    "\n",
    "```yaml\n",
    "input:                    # Data sources and paths\n",
    "job:                      # Job identification and output\n",
    "model_api:                # Your MGPT model server settings\n",
    "pipeline_stages:          # Which stages to run\n",
    "data_processing:          # Data validation and processing\n",
    "embedding_generation:     # Embedding creation settings\n",
    "classification:           # Classifier training settings\n",
    "evaluation:               # Model evaluation settings\n",
    "target_word_evaluation:   # Target word method settings\n",
    "output:                   # Output directories and formats\n",
    "logging:                  # Logging configuration\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Input Configuration\n",
    "\n",
    "### Option 1: Single Dataset (Auto-Split)\n",
    "\n",
    "```yaml\n",
    "input:\n",
    "  dataset_path: \"data/medical_claims.csv\"  # üëà Your CSV file\n",
    "  split_ratio: 0.8                        # 80% train, 20% test\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- You have one CSV file with all your data\n",
    "- You want automatic stratified train/test splitting\n",
    "- Most common scenario for new projects\n",
    "\n",
    "**Split ratio options:**\n",
    "- `0.7`: 70% train, 30% test (smaller datasets)\n",
    "- `0.8`: 80% train, 20% test (recommended)\n",
    "- `0.9`: 90% train, 10% test (large datasets)\n",
    "\n",
    "### Option 2: Separate Train/Test Files\n",
    "\n",
    "```yaml\n",
    "input:\n",
    "  train_dataset_path: \"data/train_claims.csv\"\n",
    "  test_dataset_path: \"data/test_claims.csv\"\n",
    "  # split_ratio is ignored when using separate files\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- You have pre-split data\n",
    "- You want to maintain specific train/test distributions\n",
    "- You're comparing with previous experiments\n",
    "\n",
    "### Option 3: Pre-computed Embeddings\n",
    "\n",
    "```yaml\n",
    "input:\n",
    "  train_embeddings_path: \"outputs/job1/embeddings/train_embeddings.json\"\n",
    "  test_embeddings_path: \"outputs/job1/embeddings/test_embeddings.json\"\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- Skip expensive embedding generation\n",
    "- Experiment with different classifiers\n",
    "- Use embeddings from previous runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Job Configuration\n",
    "\n",
    "```yaml\n",
    "job:\n",
    "  name: \"diabetes_prediction_v2\"    # üëà Descriptive job name\n",
    "  output_dir: \"outputs\"             # Base output directory\n",
    "  random_seed: 42                   # Reproducible results\n",
    "```\n",
    "\n",
    "### Job Naming Best Practices:\n",
    "\n",
    "```yaml\n",
    "# Good job names:\n",
    "name: \"diabetes_codes_full_pipeline\"     # Clear purpose\n",
    "name: \"cardiovascular_risk_embeddings\"   # Specific condition\n",
    "name: \"claim_classification_v3\"          # Version tracking\n",
    "name: \"emergency_dept_target_eval\"       # Department specific\n",
    "\n",
    "# Avoid:\n",
    "name: \"test\"                             # Too generic\n",
    "name: \"mgpt_eval_job\"                    # Default name\n",
    "name: \"run1\"                             # Not descriptive\n",
    "```\n",
    "\n",
    "### Output Structure:\n",
    "```\n",
    "outputs/\n",
    "‚îî‚îÄ‚îÄ {job.name}/                    # Your job name becomes folder\n",
    "    ‚îú‚îÄ‚îÄ embeddings/\n",
    "    ‚îú‚îÄ‚îÄ models/\n",
    "    ‚îú‚îÄ‚îÄ metrics/\n",
    "    ‚îú‚îÄ‚îÄ summary/\n",
    "    ‚îî‚îÄ‚îÄ logs/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Model API Configuration\n",
    "\n",
    "```yaml\n",
    "model_api:\n",
    "  base_url: \"http://localhost:8000\"        # üëà Your model server URL\n",
    "  batch_size: 32                           # Requests per batch\n",
    "  timeout: 300                             # 5 minute timeout\n",
    "  max_retries: 3                           # Retry attempts\n",
    "```\n",
    "\n",
    "### Server URL Examples:\n",
    "\n",
    "```yaml\n",
    "# Local development\n",
    "base_url: \"http://localhost:8000\"\n",
    "\n",
    "# Remote server\n",
    "base_url: \"https://mgpt-api.yourcompany.com\"\n",
    "\n",
    "# Docker container\n",
    "base_url: \"http://mgpt-container:8000\"\n",
    "\n",
    "# Cloud deployment\n",
    "base_url: \"https://mgpt-api.cloud.example.com\"\n",
    "```\n",
    "\n",
    "### Batch Size Tuning:\n",
    "\n",
    "| Server Capacity | Recommended batch_size | Use Case |\n",
    "|----------------|------------------------|----------|\n",
    "| Small (1-2 GB RAM) | 8-16 | Development, testing |\n",
    "| Medium (4-8 GB RAM) | 32-64 | Production, medium datasets |\n",
    "| Large (16+ GB RAM) | 64-128 | Large-scale production |\n",
    "\n",
    "### Timeout Settings:\n",
    "\n",
    "```yaml\n",
    "# For embedding generation\n",
    "timeout: 300      # 5 minutes (recommended)\n",
    "\n",
    "# For text generation (slower)\n",
    "timeout: 600      # 10 minutes\n",
    "\n",
    "# For very large batches\n",
    "timeout: 1200     # 20 minutes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Pipeline Stages Configuration\n",
    "\n",
    "```yaml\n",
    "pipeline_stages:\n",
    "  embeddings: true           # Generate embeddings from text\n",
    "  classification: true       # Train ML classifiers\n",
    "  evaluation: true           # Evaluate trained models\n",
    "  target_word_eval: true     # Run target word evaluation\n",
    "  summary_report: true       # Create summary report\n",
    "  method_comparison: true    # Compare both methods\n",
    "```\n",
    "\n",
    "### Common Stage Combinations:\n",
    "\n",
    "#### 1. Embeddings Only\n",
    "```yaml\n",
    "pipeline_stages:\n",
    "  embeddings: true\n",
    "  classification: false\n",
    "  evaluation: false\n",
    "  target_word_eval: false\n",
    "  summary_report: false\n",
    "  method_comparison: false\n",
    "```\n",
    "**Use case**: Generate embeddings for later use\n",
    "\n",
    "#### 2. Classification from Embeddings\n",
    "```yaml\n",
    "pipeline_stages:\n",
    "  embeddings: false          # Use existing embeddings\n",
    "  classification: true\n",
    "  evaluation: true\n",
    "  target_word_eval: false\n",
    "  summary_report: true\n",
    "  method_comparison: false\n",
    "```\n",
    "**Use case**: Train classifiers on pre-computed embeddings\n",
    "\n",
    "#### 3. Target Word Only\n",
    "```yaml\n",
    "pipeline_stages:\n",
    "  embeddings: false\n",
    "  classification: false\n",
    "  evaluation: false\n",
    "  target_word_eval: true\n",
    "  summary_report: true\n",
    "  method_comparison: false\n",
    "```\n",
    "**Use case**: Quick evaluation using target codes\n",
    "\n",
    "#### 4. Full Comparison\n",
    "```yaml\n",
    "pipeline_stages:\n",
    "  embeddings: true\n",
    "  classification: true\n",
    "  evaluation: true\n",
    "  target_word_eval: true\n",
    "  summary_report: true\n",
    "  method_comparison: true    # üëà Compare both methods\n",
    "```\n",
    "**Use case**: Comprehensive evaluation and method comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Embedding Generation Configuration\n",
    "\n",
    "```yaml\n",
    "embedding_generation:\n",
    "  batch_size: 16                           # Claims per processing batch\n",
    "  save_interval: 100                       # Save progress every N batches\n",
    "  checkpoint_dir: \"outputs/checkpoints\"    # Checkpoint directory\n",
    "  resume_from_checkpoint: true             # Resume if interrupted\n",
    "  tokenizer_path: \"/app/tokenizer\"         # Path to tokenizer\n",
    "```\n",
    "\n",
    "### Data Processing Settings\n",
    "\n",
    "```yaml\n",
    "data_processing:\n",
    "  random_seed: 42\n",
    "  max_sequence_length: 512          # Maximum tokens per claim\n",
    "  include_mcid: true                # Include Medical Claim IDs\n",
    "  output_format: \"json\"             # json or csv\n",
    "  train_test_split: 0.8             # Fallback split ratio\n",
    "```\n",
    "\n",
    "### Sequence Length Guidelines:\n",
    "\n",
    "| Sequence Length | Typical Use Case | Memory Impact |\n",
    "|----------------|------------------|---------------|\n",
    "| 128 | Short claims, fast processing | Low |\n",
    "| 256 | Medium claims, balanced | Medium |\n",
    "| 512 | Long claims, comprehensive | High |\n",
    "| 1024+ | Very long claims, research | Very High |\n",
    "\n",
    "### Output Format Comparison:\n",
    "\n",
    "```yaml\n",
    "# JSON format (default)\n",
    "output_format: \"json\"\n",
    "# Pros: Human readable, includes metadata\n",
    "# Cons: Larger file size\n",
    "# Use for: Development, small-medium datasets\n",
    "\n",
    "# CSV format\n",
    "output_format: \"csv\"\n",
    "# Pros: Compact, efficient loading\n",
    "# Cons: Less metadata\n",
    "# Use for: Large datasets, production\n",
    "```\n",
    "\n",
    "### Checkpoint Configuration:\n",
    "\n",
    "```yaml\n",
    "# For large datasets (10,000+ claims)\n",
    "save_interval: 50             # More frequent saves\n",
    "\n",
    "# For medium datasets (1,000-10,000 claims)\n",
    "save_interval: 100            # Balanced frequency\n",
    "\n",
    "# For small datasets (<1,000 claims)\n",
    "save_interval: 200            # Less frequent saves\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Classification Configuration\n",
    "\n",
    "```yaml\n",
    "classification:\n",
    "  models: [\"logistic_regression\", \"svm\", \"random_forest\"]\n",
    "  \n",
    "  cross_validation:\n",
    "    n_folds: 5                          # CV folds\n",
    "    scoring: \"roc_auc\"                  # Optimization metric\n",
    "    n_jobs: -1                          # Parallel jobs\n",
    "  \n",
    "  hyperparameter_search:\n",
    "    # Detailed hyperparameter grids...\n",
    "```\n",
    "\n",
    "### Model Selection Guide:\n",
    "\n",
    "#### Logistic Regression\n",
    "```yaml\n",
    "models: [\"logistic_regression\"]\n",
    "hyperparameter_search:\n",
    "  logistic_regression:\n",
    "    C: [0.001, 0.01, 0.1, 1, 10, 100]     # Regularization strength\n",
    "    penalty: [\"l1\", \"l2\"]                  # Regularization type\n",
    "    solver: [\"liblinear\", \"saga\"]          # Optimization algorithm\n",
    "```\n",
    "**Best for**: Fast training, interpretable results, linear relationships\n",
    "\n",
    "#### Support Vector Machine\n",
    "```yaml\n",
    "models: [\"svm\"]\n",
    "hyperparameter_search:\n",
    "  svm:\n",
    "    C: [0.1, 1, 10]                        # Regularization\n",
    "    kernel: [\"rbf\", \"linear\"]              # Kernel type\n",
    "    gamma: [\"scale\", \"auto\"]               # Kernel coefficient\n",
    "```\n",
    "**Best for**: High-dimensional data, robust to overfitting, non-linear patterns\n",
    "\n",
    "#### Random Forest\n",
    "```yaml\n",
    "models: [\"random_forest\"]\n",
    "hyperparameter_search:\n",
    "  random_forest:\n",
    "    n_estimators: [100, 200, 300]         # Number of trees\n",
    "    max_depth: [10, 20, 30, null]         # Tree depth\n",
    "    min_samples_split: [2, 5, 10]         # Split threshold\n",
    "```\n",
    "**Best for**: Robust predictions, feature importance, noisy data\n",
    "\n",
    "### Cross-Validation Settings:\n",
    "\n",
    "```yaml\n",
    "cross_validation:\n",
    "  # Small datasets (<1,000 samples)\n",
    "  n_folds: 3\n",
    "  \n",
    "  # Medium datasets (1,000-10,000 samples)\n",
    "  n_folds: 5                    # Recommended\n",
    "  \n",
    "  # Large datasets (>10,000 samples)\n",
    "  n_folds: 10\n",
    "  \n",
    "  # Scoring options\n",
    "  scoring: \"roc_auc\"             # Best for binary classification\n",
    "  scoring: \"accuracy\"            # Simple overall correctness\n",
    "  scoring: \"f1\"                  # Balance precision/recall\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Evaluation Configuration\n",
    "\n",
    "```yaml\n",
    "evaluation:\n",
    "  metrics: [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"roc_auc\", \"confusion_matrix\"]\n",
    "  \n",
    "  visualization:\n",
    "    generate_plots: true\n",
    "    plot_formats: [\"png\", \"pdf\"]\n",
    "    dpi: 300\n",
    "```\n",
    "\n",
    "### Metrics Selection Guide:\n",
    "\n",
    "```yaml\n",
    "# For balanced datasets\n",
    "metrics: [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"roc_auc\"]\n",
    "\n",
    "# For imbalanced datasets (focus on minority class)\n",
    "metrics: [\"precision\", \"recall\", \"f1_score\", \"roc_auc\", \"confusion_matrix\"]\n",
    "\n",
    "# For clinical applications (avoid missing positives)\n",
    "metrics: [\"recall\", \"f1_score\", \"roc_auc\", \"confusion_matrix\"]\n",
    "\n",
    "# For research (comprehensive analysis)\n",
    "metrics: [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"roc_auc\", \"confusion_matrix\"]\n",
    "```\n",
    "\n",
    "### Visualization Options:\n",
    "\n",
    "```yaml\n",
    "visualization:\n",
    "  generate_plots: true\n",
    "  \n",
    "  # For presentations/web\n",
    "  plot_formats: [\"png\"]\n",
    "  dpi: 150\n",
    "  \n",
    "  # For publications\n",
    "  plot_formats: [\"pdf\", \"png\"]\n",
    "  dpi: 300\n",
    "  \n",
    "  # For high-quality prints\n",
    "  plot_formats: [\"pdf\", \"eps\"]\n",
    "  dpi: 600\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Target Word Evaluation Configuration\n",
    "\n",
    "```yaml\n",
    "target_word_evaluation:\n",
    "  enable: true\n",
    "  \n",
    "  # Method 1: Direct list\n",
    "  target_codes: [\"E119\", \"76642\", \"N6320\", \"K9289\"]\n",
    "  \n",
    "  # Method 2: Load from file\n",
    "  # target_codes_file: \"configs/target_codes.txt\"\n",
    "  \n",
    "  generations_per_prompt: 10        # Robustness vs speed\n",
    "  max_new_tokens: 200               # Length of generation\n",
    "  temperature: 0.8                  # Sampling creativity\n",
    "  top_k: 50                        # Vocabulary diversity\n",
    "  search_method: \"exact\"            # Matching precision\n",
    "```\n",
    "\n",
    "### Target Code Selection Guidelines:\n",
    "\n",
    "#### Clinical Condition Codes:\n",
    "```yaml\n",
    "# Diabetes-related codes\n",
    "target_codes: [\"E119\", \"E1022\", \"E1040\", \"E1051\", \"E1059\"]\n",
    "\n",
    "# Cardiovascular codes\n",
    "target_codes: [\"I10\", \"I259\", \"E785\", \"Z87891\", \"I110\"]\n",
    "\n",
    "# Emergency department codes\n",
    "target_codes: [\"R50\", \"R06\", \"R060\", \"R509\", \"G9340\"]\n",
    "```\n",
    "\n",
    "#### Code Frequency Considerations:\n",
    "```yaml\n",
    "# High-frequency codes (appear in >10% of data)\n",
    "target_codes: [\"Z0000\", \"M549\", \"R50\"]     # May cause high false positives\n",
    "\n",
    "# Medium-frequency codes (appear in 1-10% of data)\n",
    "target_codes: [\"E119\", \"I10\", \"N6320\"]     # Balanced (recommended)\n",
    "\n",
    "# Low-frequency codes (appear in <1% of data)\n",
    "target_codes: [\"O0903\", \"Z87891\"]          # May cause low recall\n",
    "```\n",
    "\n",
    "### Generation Parameters Tuning:\n",
    "\n",
    "#### For Speed (Quick Testing):\n",
    "```yaml\n",
    "generations_per_prompt: 5\n",
    "max_new_tokens: 100\n",
    "temperature: 0.7\n",
    "top_k: 30\n",
    "```\n",
    "\n",
    "#### For Accuracy (Production):\n",
    "```yaml\n",
    "generations_per_prompt: 15\n",
    "max_new_tokens: 300\n",
    "temperature: 0.8\n",
    "top_k: 50\n",
    "```\n",
    "\n",
    "#### For Robustness (Research):\n",
    "```yaml\n",
    "generations_per_prompt: 20\n",
    "max_new_tokens: 400\n",
    "temperature: 0.9\n",
    "top_k: 100\n",
    "```\n",
    "\n",
    "### Target Codes File Format:\n",
    "\n",
    "**File: `configs/target_codes.txt`**\n",
    "```\n",
    "# Diabetes-related codes\n",
    "E119      # Type 2 diabetes mellitus without complications\n",
    "E1022     # Type 1 diabetes mellitus with diabetic chronic kidney disease\n",
    "E1040     # Type 1 diabetes mellitus with diabetic neuropathy\n",
    "\n",
    "# Cardiovascular codes\n",
    "I10       # Essential hypertension\n",
    "I259      # Chronic ischemic heart disease, unspecified\n",
    "E785      # Hyperlipidemia, unspecified\n",
    "\n",
    "# Lines starting with # are comments\n",
    "# Empty lines are ignored\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Output Configuration\n",
    "\n",
    "```yaml\n",
    "output:\n",
    "  embeddings_dir: \"outputs/embeddings\"     # Embedding files\n",
    "  models_dir: \"outputs/models\"              # Trained models\n",
    "  metrics_dir: \"outputs/metrics\"            # Evaluation results\n",
    "  logs_dir: \"outputs/logs\"                  # Log files\n",
    "  save_best_model_only: false              # Save all vs best only\n",
    "  model_format: \"pickle\"                    # pickle or joblib\n",
    "```\n",
    "\n",
    "### Directory Structure:\n",
    "```\n",
    "outputs/{job.name}/\n",
    "‚îú‚îÄ‚îÄ embeddings/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train_embeddings.{format}\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test_embeddings.{format}\n",
    "‚îú‚îÄ‚îÄ models/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ logistic_regression_model.pkl\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ svm_model.pkl\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ random_forest_model.pkl\n",
    "‚îú‚îÄ‚îÄ metrics/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ logistic_regression/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ svm/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ random_forest/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ target_word_evaluation/\n",
    "‚îú‚îÄ‚îÄ summary/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ pipeline_summary.json\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ method_comparison.json\n",
    "‚îî‚îÄ‚îÄ logs/\n",
    "    ‚îî‚îÄ‚îÄ pipeline.log\n",
    "```\n",
    "\n",
    "### Model Storage Options:\n",
    "\n",
    "```yaml\n",
    "# Save all trained models (recommended for analysis)\n",
    "save_best_model_only: false\n",
    "\n",
    "# Save only best performing model (saves disk space)\n",
    "save_best_model_only: true\n",
    "\n",
    "# Model serialization format\n",
    "model_format: \"pickle\"    # Standard Python, smaller files\n",
    "model_format: \"joblib\"    # Better for large numpy arrays\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Logging Configuration\n",
    "\n",
    "```yaml\n",
    "logging:\n",
    "  level: \"INFO\"                             # File log level\n",
    "  console_level: \"INFO\"                     # Console log level\n",
    "  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "  file: \"outputs/logs/pipeline.log\"         # Log file path\n",
    "```\n",
    "\n",
    "### Log Level Guidelines:\n",
    "\n",
    "#### Development & Debugging:\n",
    "```yaml\n",
    "logging:\n",
    "  level: \"DEBUG\"           # Detailed information\n",
    "  console_level: \"INFO\"    # Less console noise\n",
    "```\n",
    "\n",
    "#### Production:\n",
    "```yaml\n",
    "logging:\n",
    "  level: \"INFO\"            # Important events only\n",
    "  console_level: \"WARNING\" # Minimal console output\n",
    "```\n",
    "\n",
    "#### Research/Analysis:\n",
    "```yaml\n",
    "logging:\n",
    "  level: \"INFO\"            # Balanced detail\n",
    "  console_level: \"INFO\"    # See progress\n",
    "```\n",
    "\n",
    "### Log Levels Explained:\n",
    "\n",
    "| Level | What it logs | Use case |\n",
    "|-------|-------------|----------|\n",
    "| DEBUG | Everything (API calls, data processing) | Debugging issues |\n",
    "| INFO | Major steps, progress, results | Normal operation |\n",
    "| WARNING | Issues that don't stop execution | Production monitoring |\n",
    "| ERROR | Errors that stop execution | Critical issues only |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Template-Based Configuration\n",
    "\n",
    "### Starting with Templates:\n",
    "\n",
    "1. **Copy a template:**\n",
    "   ```bash\n",
    "   cp configs/templates/04_full_pipeline.yaml my_config.yaml\n",
    "   ```\n",
    "\n",
    "2. **Edit key fields marked with üëà:**\n",
    "   ```yaml\n",
    "   input:\n",
    "     dataset_path: \"data/my_claims.csv\"  # üëà UPDATE\n",
    "   \n",
    "   model_api:\n",
    "     base_url: \"http://my-server:8000\"   # üëà UPDATE\n",
    "   \n",
    "   target_word_evaluation:\n",
    "     target_codes: [\"E119\", \"I10\"]       # üëà UPDATE\n",
    "   ```\n",
    "\n",
    "3. **Run the pipeline:**\n",
    "   ```bash\n",
    "   python main.py run-all --config my_config.yaml\n",
    "   ```\n",
    "\n",
    "### Template Selection Guide:\n",
    "\n",
    "| Template | Purpose | Required Updates |\n",
    "|----------|---------|------------------|\n",
    "| `01_embeddings_only.yaml` | Generate embeddings | dataset_path, base_url |\n",
    "| `02_from_embeddings.yaml` | Train classifiers | embedding paths |\n",
    "| `03_target_words_only.yaml` | Target evaluation | dataset_path, base_url, target_codes |\n",
    "| `04_full_pipeline.yaml` | Complete analysis | dataset_path, base_url, target_codes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Performance Optimization\n",
    "\n",
    "### For Large Datasets (>10,000 claims):\n",
    "\n",
    "```yaml\n",
    "model_api:\n",
    "  batch_size: 64              # Larger batches\n",
    "  timeout: 600                # Longer timeout\n",
    "\n",
    "embedding_generation:\n",
    "  batch_size: 32              # Process more at once\n",
    "  save_interval: 50           # Frequent checkpoints\n",
    "\n",
    "data_processing:\n",
    "  output_format: \"csv\"        # More efficient format\n",
    "\n",
    "classification:\n",
    "  cross_validation:\n",
    "    n_jobs: -1                # Use all CPU cores\n",
    "```\n",
    "\n",
    "### For Memory-Constrained Environments:\n",
    "\n",
    "```yaml\n",
    "model_api:\n",
    "  batch_size: 8               # Smaller batches\n",
    "\n",
    "embedding_generation:\n",
    "  batch_size: 4               # Process fewer at once\n",
    "  save_interval: 25           # More frequent saves\n",
    "\n",
    "data_processing:\n",
    "  max_sequence_length: 256    # Shorter sequences\n",
    "```\n",
    "\n",
    "### For High-Performance Systems:\n",
    "\n",
    "```yaml\n",
    "model_api:\n",
    "  batch_size: 128             # Large batches\n",
    "  timeout: 900                # Generous timeout\n",
    "\n",
    "embedding_generation:\n",
    "  batch_size: 64              # Large processing batches\n",
    "\n",
    "classification:\n",
    "  cross_validation:\n",
    "    n_jobs: -1                # All CPU cores\n",
    "    n_folds: 10               # More thorough CV\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Validation and Troubleshooting\n",
    "\n",
    "### Configuration Validation:\n",
    "\n",
    "The pipeline automatically validates your configuration and will show helpful error messages:\n",
    "\n",
    "```bash\n",
    "# Test your configuration\n",
    "python main.py validate --config my_config.yaml\n",
    "```\n",
    "\n",
    "### Common Configuration Issues:\n",
    "\n",
    "#### Missing Required Fields:\n",
    "```yaml\n",
    "# ‚ùå Error: Missing target_codes when target_word_eval is enabled\n",
    "pipeline_stages:\n",
    "  target_word_eval: true\n",
    "target_word_evaluation:\n",
    "  enable: true\n",
    "  # target_codes: []  # Missing!\n",
    "\n",
    "# ‚úÖ Fix: Provide target codes\n",
    "target_word_evaluation:\n",
    "  enable: true\n",
    "  target_codes: [\"E119\", \"I10\"]\n",
    "```\n",
    "\n",
    "#### Path Issues:\n",
    "```yaml\n",
    "# ‚ùå Error: File not found\n",
    "input:\n",
    "  dataset_path: \"data/medical_claims.csv\"  # File doesn't exist\n",
    "\n",
    "# ‚úÖ Fix: Check file path\n",
    "input:\n",
    "  dataset_path: \"../data/medical_claims.csv\"  # Correct path\n",
    "```\n",
    "\n",
    "#### Invalid Values:\n",
    "```yaml\n",
    "# ‚ùå Error: Invalid split ratio\n",
    "input:\n",
    "  split_ratio: 1.5  # Must be between 0.1 and 0.9\n",
    "\n",
    "# ‚úÖ Fix: Valid range\n",
    "input:\n",
    "  split_ratio: 0.8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Next Steps\n",
    "\n",
    "- **[05_Results_Analysis.ipynb](05_Results_Analysis.ipynb)** - Understanding your results\n",
    "- **[06_Troubleshooting.ipynb](06_Troubleshooting.ipynb)** - Common issues and solutions\n",
    "- **[07_Advanced_Usage.ipynb](07_Advanced_Usage.ipynb)** - Production deployment\n",
    "\n",
    "### Quick Reference Commands:\n",
    "\n",
    "```bash\n",
    "# Validate configuration\n",
    "python main.py validate --config my_config.yaml\n",
    "\n",
    "# Run full pipeline\n",
    "python main.py run-all --config my_config.yaml\n",
    "\n",
    "# Run specific stage\n",
    "python main.py run-embeddings --config my_config.yaml\n",
    "python main.py run-classification --config my_config.yaml\n",
    "python main.py run-evaluation --config my_config.yaml\n",
    "python main.py run-target-eval --config my_config.yaml\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}