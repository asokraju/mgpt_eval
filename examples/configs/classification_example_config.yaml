# =============================================================================
# CLASSIFICATION PIPELINE CONFIGURATION
# =============================================================================
# Pure config-driven approach for binary classification with variable references
# All parameters defined once and referenced throughout the configuration

# =============================================================================
# JOB CONFIGURATION - Base settings for the entire pipeline
# =============================================================================
job:
  name: "binary_classification_example"
  output_dir: "examples/outputs"
  random_seed: 42

# =============================================================================
# INPUT CONFIGURATION - Embeddings data sources
# =============================================================================
input:
  train_embeddings_path: "${job.output_dir}/embeddings/train_embeddings.csv"
  test_embeddings_path: "${job.output_dir}/embeddings/test_embeddings.csv"

# =============================================================================
# CLASSIFICATION CONFIGURATION - Core ML settings
# =============================================================================
classification:
  models: ["logistic_regression", "svm", "random_forest"]
  
  # Hyperparameter search grids
  hyperparameter_search:
    logistic_regression:
      C: [0.01, 0.1, 1, 10]
      penalty: ["l2"]
      solver: ["lbfgs"]
    
    svm:
      C: [0.1, 1, 10]
      kernel: ["rbf", "linear"]
      gamma: ["scale", "auto"]
    
    random_forest:
      n_estimators: [100, 200]
      max_depth: [10, 20, null]
      min_samples_split: [2, 5]
      min_samples_leaf: [1, 2]
  
  # Cross-validation settings
  cross_validation:
    n_folds: 5
    scoring: "roc_auc"
    n_jobs: -1

# =============================================================================
# OUTPUT CONFIGURATION - Directory structure using variable references
# =============================================================================
output:
  embeddings_dir: "${job.output_dir}/embeddings"
  models_dir: "${job.output_dir}/models"
  logs_dir: "${job.output_dir}/logs"

# =============================================================================
# LOGGING CONFIGURATION - Using template references for log file path
# =============================================================================
logging:
  level: "INFO"
  console_level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "${output.logs_dir}/classification_pipeline.log"
  max_file_size: "10MB"
  backup_count: 5

# =============================================================================
# CONFIGURATION NOTES
# =============================================================================
# Variable References Used:
# - ${job.name} → "binary_classification_example"
# - ${job.output_dir} → "examples/outputs"
# - ${output.embeddings_dir} → "examples/outputs/embeddings"
# - ${output.models_dir} → "examples/outputs/models"
# - ${output.logs_dir} → "examples/outputs/logs"
# 
# Input Files Expected:
# - train_embeddings.csv: Training embeddings with columns [mcid, label, embedding]
# - test_embeddings.csv: Test embeddings with columns [mcid, label, embedding]
#
# Output Structure:
# - models/: Trained models (.pkl) and metrics (.json) files
# - logs/: Classification pipeline logs
#
# Key Features:
# - Binary classification only (labels: 0, 1)
# - Multiple classifier types with hyperparameter tuning
# - Cross-validation with configurable folds and scoring
# - Automatic class imbalance detection and handling
# - Comprehensive evaluation metrics (accuracy, precision, recall, F1, ROC-AUC)
# - Config-driven paths and model naming