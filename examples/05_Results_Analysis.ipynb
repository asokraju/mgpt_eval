{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Results Analysis & Interpretation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook explains how to interpret the results from your MGPT-Eval pipeline runs. We'll cover the different types of outputs, what the metrics mean, and how to make data-driven decisions about your model's performance.\n",
    "\n",
    "## ğŸ“ Output Structure\n",
    "\n",
    "After running the pipeline, you'll find organized results in:\n",
    "\n",
    "```\n",
    "outputs/{job_name}/\n",
    "â”œâ”€â”€ ğŸ“Š metrics/                    # Detailed evaluation results\n",
    "â”‚   â”œâ”€â”€ logistic_regression/\n",
    "â”‚   â”œâ”€â”€ svm/\n",
    "â”‚   â”œâ”€â”€ random_forest/\n",
    "â”‚   â””â”€â”€ target_word_evaluation/\n",
    "â”œâ”€â”€ ğŸ“‹ summary/                    # High-level summaries\n",
    "â”‚   â”œâ”€â”€ pipeline_summary.json     # Overall results\n",
    "â”‚   â””â”€â”€ method_comparison.json    # Best method recommendation\n",
    "â”œâ”€â”€ ğŸ¤– models/                     # Trained classifiers\n",
    "â”œâ”€â”€ ğŸ“ˆ embeddings/                 # Generated embeddings\n",
    "â””â”€â”€ ğŸ“ logs/                      # Execution logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Quick Start: Key Files to Check\n",
    "\n",
    "### 1. Overall Performance Summary\n",
    "**File**: `summary/pipeline_summary.json`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"job_info\": {\n",
    "    \"name\": \"diabetes_prediction_v2\",\n",
    "    \"completion_time\": \"2024-01-15T14:30:22\",\n",
    "    \"total_runtime_minutes\": 45.2\n",
    "  },\n",
    "  \"data_summary\": {\n",
    "    \"total_samples\": 5000,\n",
    "    \"train_samples\": 4000,\n",
    "    \"test_samples\": 1000,\n",
    "    \"positive_rate\": 0.23\n",
    "  },\n",
    "  \"best_results\": {\n",
    "    \"embedding_method\": {\n",
    "      \"best_classifier\": \"svm\",\n",
    "      \"accuracy\": 0.87,\n",
    "      \"f1_score\": 0.84\n",
    "    },\n",
    "    \"target_word_method\": {\n",
    "      \"accuracy\": 0.82,\n",
    "      \"f1_score\": 0.79\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Quick Interpretation:**\n",
    "- âœ… **SVM performs best** (87% accuracy)\n",
    "- âœ… **Embedding method outperforms** target word method\n",
    "- âœ… **Good results** for 23% positive rate (imbalanced dataset)\n",
    "\n",
    "### 2. Method Comparison & Recommendation\n",
    "**File**: `summary/method_comparison.json`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"comparison_results\": {\n",
    "    \"embedding_method\": {\n",
    "      \"accuracy\": 0.87,\n",
    "      \"precision\": 0.85,\n",
    "      \"recall\": 0.83,\n",
    "      \"f1_score\": 0.84,\n",
    "      \"roc_auc\": 0.91\n",
    "    },\n",
    "    \"target_word_method\": {\n",
    "      \"accuracy\": 0.82,\n",
    "      \"precision\": 0.78,\n",
    "      \"recall\": 0.80,\n",
    "      \"f1_score\": 0.79,\n",
    "      \"roc_auc\": 0.86\n",
    "    },\n",
    "    \"statistical_significance\": {\n",
    "      \"p_value\": 0.003,\n",
    "      \"is_significant\": true,\n",
    "      \"confidence_level\": 0.95\n",
    "    }\n",
    "  },\n",
    "  \"recommendation\": {\n",
    "    \"best_method\": \"embedding_method\",\n",
    "    \"reason\": \"Significantly higher performance across all metrics\",\n",
    "    \"confidence\": \"high\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "- ğŸ† **Embedding method recommended** (statistically significant)\n",
    "- ğŸ“Š **5% accuracy improvement** over target word method\n",
    "- ğŸ”¬ **High confidence** (p < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Embedding-Based Classification Results\n",
    "\n",
    "### Individual Classifier Performance\n",
    "\n",
    "Each classifier gets its own directory with detailed results:\n",
    "\n",
    "#### Logistic Regression Results\n",
    "**File**: `metrics/logistic_regression/metrics.json`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"model_info\": {\n",
    "    \"model_type\": \"logistic_regression\",\n",
    "    \"best_hyperparameters\": {\n",
    "      \"C\": 1.0,\n",
    "      \"penalty\": \"l2\",\n",
    "      \"solver\": \"liblinear\"\n",
    "    },\n",
    "    \"cv_score\": 0.85,\n",
    "    \"training_time_seconds\": 12.3\n",
    "  },\n",
    "  \"test_performance\": {\n",
    "    \"accuracy\": 0.84,\n",
    "    \"precision\": 0.82,\n",
    "    \"recall\": 0.81,\n",
    "    \"f1_score\": 0.81,\n",
    "    \"roc_auc\": 0.89\n",
    "  },\n",
    "  \"confusion_matrix\": {\n",
    "    \"true_negative\": 752,\n",
    "    \"false_positive\": 18,\n",
    "    \"false_negative\": 44,\n",
    "    \"true_positive\": 186\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### SVM Results\n",
    "**File**: `metrics/svm/metrics.json`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"model_info\": {\n",
    "    \"model_type\": \"svm\",\n",
    "    \"best_hyperparameters\": {\n",
    "      \"C\": 10,\n",
    "      \"kernel\": \"rbf\",\n",
    "      \"gamma\": \"scale\"\n",
    "    },\n",
    "    \"cv_score\": 0.87,\n",
    "    \"training_time_seconds\": 45.1\n",
    "  },\n",
    "  \"test_performance\": {\n",
    "    \"accuracy\": 0.87,\n",
    "    \"precision\": 0.85,\n",
    "    \"recall\": 0.83,\n",
    "    \"f1_score\": 0.84,\n",
    "    \"roc_auc\": 0.91\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Random Forest Results\n",
    "**File**: `metrics/random_forest/metrics.json`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"model_info\": {\n",
    "    \"model_type\": \"random_forest\",\n",
    "    \"best_hyperparameters\": {\n",
    "      \"n_estimators\": 200,\n",
    "      \"max_depth\": 20,\n",
    "      \"min_samples_split\": 5\n",
    "    },\n",
    "    \"cv_score\": 0.83,\n",
    "    \"training_time_seconds\": 78.5\n",
    "  },\n",
    "  \"test_performance\": {\n",
    "    \"accuracy\": 0.82,\n",
    "    \"precision\": 0.79,\n",
    "    \"recall\": 0.85,\n",
    "    \"f1_score\": 0.82,\n",
    "    \"roc_auc\": 0.88\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Classifier Comparison Analysis\n",
    "\n",
    "| Classifier | Accuracy | Precision | Recall | F1-Score | ROC-AUC | Training Time |\n",
    "|------------|----------|-----------|--------|----------|---------|---------------|\n",
    "| **SVM** | **0.87** | **0.85** | 0.83 | **0.84** | **0.91** | 45.1s |\n",
    "| Logistic Regression | 0.84 | 0.82 | 0.81 | 0.81 | 0.89 | **12.3s** |\n",
    "| Random Forest | 0.82 | 0.79 | **0.85** | 0.82 | 0.88 | 78.5s |\n",
    "\n",
    "**Insights:**\n",
    "- ğŸ† **SVM wins overall** (highest accuracy, precision, F1, ROC-AUC)\n",
    "- âš¡ **Logistic Regression fastest** (good for real-time applications)\n",
    "- ğŸ¯ **Random Forest best recall** (finds most positive cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Target Word Evaluation Results\n",
    "\n",
    "### Summary Results\n",
    "**File**: `metrics/target_word_evaluation/target_word_eval_summary.json`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"overall_metrics\": {\n",
    "    \"accuracy\": 0.82,\n",
    "    \"precision\": 0.78,\n",
    "    \"recall\": 0.80,\n",
    "    \"f1_score\": 0.79,\n",
    "    \"total_samples\": 1000,\n",
    "    \"positive_predictions\": 245,\n",
    "    \"negative_predictions\": 755\n",
    "  },\n",
    "  \"target_code_analysis\": {\n",
    "    \"E119\": {\n",
    "      \"found_count\": 87,\n",
    "      \"percentage\": 8.7,\n",
    "      \"avg_generations_when_found\": 3.2\n",
    "    },\n",
    "    \"76642\": {\n",
    "      \"found_count\": 62,\n",
    "      \"percentage\": 6.2,\n",
    "      \"avg_generations_when_found\": 2.8\n",
    "    },\n",
    "    \"N6320\": {\n",
    "      \"found_count\": 45,\n",
    "      \"percentage\": 4.5,\n",
    "      \"avg_generations_when_found\": 2.1\n",
    "    },\n",
    "    \"K9289\": {\n",
    "      \"found_count\": 51,\n",
    "      \"percentage\": 5.1,\n",
    "      \"avg_generations_when_found\": 2.5\n",
    "    }\n",
    "  },\n",
    "  \"generation_statistics\": {\n",
    "    \"avg_generations_per_sample\": 10,\n",
    "    \"avg_positive_generations_per_positive_sample\": 2.7,\n",
    "    \"avg_tokens_generated\": 185,\n",
    "    \"total_api_calls\": 10000,\n",
    "    \"total_tokens_generated\": 1850000\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Detailed Predictions\n",
    "**File**: `metrics/target_word_evaluation/target_word_predictions.csv`\n",
    "\n",
    "```csv\n",
    "mcid,true_label,predicted_label,found_codes,positive_generations,total_generations,prediction_confidence\n",
    "CLAIM_001,1,1,\"['E119', '76642']\",4,10,0.4\n",
    "CLAIM_002,0,0,\"[]\",0,10,0.0\n",
    "CLAIM_003,1,1,\"['N6320']\",2,10,0.2\n",
    "CLAIM_004,1,0,\"[]\",0,10,0.0\n",
    "CLAIM_005,0,1,\"['K9289']\",1,10,0.1\n",
    "```\n",
    "\n",
    "### Target Code Performance Analysis\n",
    "\n",
    "| Target Code | Description | Found % | Avg Generations | Clinical Relevance |\n",
    "|-------------|-------------|---------|----------------|--------------------|\n",
    "| **E119** | Type 2 diabetes | **8.7%** | 3.2 | High predictive value |\n",
    "| **76642** | Diagnostic ultrasound | 6.2% | 2.8 | Good consistency |\n",
    "| **K9289** | Digestive system | 5.1% | 2.5 | Moderate relevance |\n",
    "| **N6320** | Urological condition | 4.5% | 2.1 | Lower frequency |\n",
    "\n",
    "**Insights:**\n",
    "- ğŸ¯ **E119 most predictive** (appears in 8.7% of samples)\n",
    "- ğŸ“Š **Consistent generation** (2-3 generations when found)\n",
    "- ğŸ” **Model understands medical context** (realistic code co-occurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Performance Metrics Deep Dive\n",
    "\n",
    "### Understanding the Metrics\n",
    "\n",
    "#### Accuracy\n",
    "```\n",
    "Accuracy = (True Positives + True Negatives) / Total Samples\n",
    "```\n",
    "- **High accuracy (>85%)**: Excellent overall performance\n",
    "- **Medium accuracy (70-85%)**: Good performance, room for improvement\n",
    "- **Low accuracy (<70%)**: Needs investigation\n",
    "\n",
    "#### Precision\n",
    "```\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "```\n",
    "- **High precision**: Few false alarms (important for clinical decisions)\n",
    "- **Low precision**: Many false positives (over-diagnosis risk)\n",
    "\n",
    "#### Recall (Sensitivity)\n",
    "```\n",
    "Recall = True Positives / (True Positives + False Negatives)\n",
    "```\n",
    "- **High recall**: Catches most positive cases (important for screening)\n",
    "- **Low recall**: Misses positive cases (under-diagnosis risk)\n",
    "\n",
    "#### F1-Score\n",
    "```\n",
    "F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)\n",
    "```\n",
    "- **Balanced metric**: Good when precision and recall are both important\n",
    "- **Higher F1**: Better overall balance\n",
    "\n",
    "#### ROC-AUC\n",
    "- **0.9-1.0**: Excellent discrimination\n",
    "- **0.8-0.9**: Good discrimination\n",
    "- **0.7-0.8**: Fair discrimination\n",
    "- **0.5-0.7**: Poor discrimination\n",
    "- **0.5**: Random performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical Context Interpretation\n",
    "\n",
    "#### For Screening Applications (Prioritize Recall)\n",
    "```json\n",
    "{\n",
    "  \"accuracy\": 0.78,\n",
    "  \"precision\": 0.72,\n",
    "  \"recall\": 0.92,     // â† Most important\n",
    "  \"f1_score\": 0.81\n",
    "}\n",
    "```\n",
    "**Interpretation**: Good for screening - catches 92% of positive cases, acceptable false positive rate\n",
    "\n",
    "#### For Diagnostic Support (Prioritize Precision)\n",
    "```json\n",
    "{\n",
    "  \"accuracy\": 0.88,\n",
    "  \"precision\": 0.94,   // â† Most important\n",
    "  \"recall\": 0.76,\n",
    "  \"f1_score\": 0.84\n",
    "}\n",
    "```\n",
    "**Interpretation**: Good for diagnosis support - 94% of positive predictions are correct\n",
    "\n",
    "#### For Research (Balanced Performance)\n",
    "```json\n",
    "{\n",
    "  \"accuracy\": 0.85,\n",
    "  \"precision\": 0.83,\n",
    "  \"recall\": 0.87,\n",
    "  \"f1_score\": 0.85    // â† Most important\n",
    "}\n",
    "```\n",
    "**Interpretation**: Well-balanced performance suitable for research applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Confusion Matrix Analysis\n",
    "\n",
    "### Understanding the Confusion Matrix\n",
    "\n",
    "```\n",
    "                 Predicted\n",
    "              Negative  Positive\n",
    "Actual Negative   752      18    (TN=752, FP=18)\n",
    "       Positive    44     186    (FN=44, TP=186)\n",
    "```\n",
    "\n",
    "### Key Insights from Confusion Matrix:\n",
    "\n",
    "#### True Negatives (TN = 752)\n",
    "- **What it means**: 752 negative cases correctly identified\n",
    "- **Clinical impact**: Patients without condition correctly identified\n",
    "- **Good performance**: High TN means good specificity\n",
    "\n",
    "#### False Positives (FP = 18)\n",
    "- **What it means**: 18 negative cases incorrectly labeled as positive\n",
    "- **Clinical impact**: Unnecessary follow-up, patient anxiety\n",
    "- **Low FP**: Good precision (18/204 = 8.8% false positive rate)\n",
    "\n",
    "#### False Negatives (FN = 44)\n",
    "- **What it means**: 44 positive cases missed\n",
    "- **Clinical impact**: Missed diagnoses, delayed treatment\n",
    "- **Moderate FN**: 19.1% of positive cases missed (44/230)\n",
    "\n",
    "#### True Positives (TP = 186)\n",
    "- **What it means**: 186 positive cases correctly identified\n",
    "- **Clinical impact**: Timely diagnosis and treatment\n",
    "- **Good performance**: 80.9% sensitivity (186/230)\n",
    "\n",
    "### Clinical Decision Making:\n",
    "\n",
    "```python\n",
    "# Calculate key rates\n",
    "sensitivity = TP / (TP + FN) = 186 / 230 = 0.809  # 80.9%\n",
    "specificity = TN / (TN + FP) = 752 / 770 = 0.977  # 97.7%\n",
    "precision = TP / (TP + FP) = 186 / 204 = 0.912    # 91.2%\n",
    "```\n",
    "\n",
    "**Clinical Interpretation**:\n",
    "- âœ… **High specificity (97.7%)**: Very few false alarms\n",
    "- âœ… **High precision (91.2%)**: Positive predictions very reliable\n",
    "- âš ï¸ **Moderate sensitivity (80.9%)**: Misses some positive cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Visualizations Analysis\n",
    "\n",
    "### ROC Curves\n",
    "**Files**: `metrics/*/roc_curve.png`\n",
    "\n",
    "**How to interpret**:\n",
    "- **Curve closer to top-left**: Better performance\n",
    "- **Area under curve (AUC)**: Overall discrimination ability\n",
    "- **Diagonal line**: Random performance\n",
    "\n",
    "```\n",
    "ROC Curve Analysis:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ 1.0 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â† Perfect classifier\n",
    "â”‚     â”‚                 â”‚ â”‚\n",
    "â”‚ 0.8 â”‚     SVM â”€â”€â”€â”€â”€â”€â” â”‚ â”‚  â† Your SVM (AUC=0.91)\n",
    "â”‚     â”‚    â•±           â”‚ â”‚ â”‚\n",
    "â”‚ 0.6 â”‚  â•±   LR â”€â”€â”€â”€â”€â”€â”â”‚ â”‚ â”‚  â† Logistic Regression (AUC=0.89)\n",
    "â”‚     â”‚â•±              â”‚â”‚ â”‚ â”‚\n",
    "â”‚ 0.4 â•±      RF â”€â”€â”€â”€â”€â”€â”â”‚ â”‚ â”‚  â† Random Forest (AUC=0.88)\n",
    "â”‚    â•±               â”‚â”‚ â”‚ â”‚ â”‚\n",
    "â”‚ 0.2 â•± Random â”€â”€â”€â”€â”€â”€â”â”‚ â”‚ â”‚ â”‚  â† Random classifier (AUC=0.5)\n",
    "â”‚   â•±                â”‚â”‚ â”‚ â”‚ â”‚\n",
    "â”‚ 0.0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚ â”‚ â”‚\n",
    "â”‚     0.0  0.2  0.4  0.6 0.8 1.0\n",
    "â”‚           False Positive Rate\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Confusion Matrix Heatmaps\n",
    "**Files**: `metrics/*/confusion_matrix.png`\n",
    "\n",
    "**Visual interpretation**:\n",
    "- **Darker diagonal**: Better performance\n",
    "- **Lighter off-diagonal**: Fewer errors\n",
    "- **Normalized view**: Shows percentage distributions\n",
    "\n",
    "### Feature Importance (Random Forest)\n",
    "**Files**: `metrics/random_forest/feature_importance.png`\n",
    "\n",
    "**Shows which embedding dimensions are most predictive**:\n",
    "- High importance â†’ That dimension captures relevant medical patterns\n",
    "- Low importance â†’ That dimension is less relevant for your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Error Analysis\n",
    "\n",
    "### False Positive Analysis\n",
    "\n",
    "**Sample false positives from target word evaluation**:\n",
    "```csv\n",
    "mcid,true_label,predicted_label,found_codes,input_claim\n",
    "FP_001,0,1,\"['E119']\",\"K9289 G0378 |eoc| Z91048 M1710\"\n",
    "FP_002,0,1,\"['N6320']\",\"R50 76642 |eoc| K9289 O0903\"\n",
    "```\n",
    "\n",
    "**Possible causes**:\n",
    "1. **Model hallucination**: Generating codes not in input\n",
    "2. **Label quality**: True label might be incorrect\n",
    "3. **Target code selection**: Codes might be too general\n",
    "\n",
    "### False Negative Analysis\n",
    "\n",
    "**Sample false negatives from target word evaluation**:\n",
    "```csv\n",
    "mcid,true_label,predicted_label,found_codes,input_claim\n",
    "FN_001,1,0,\"[]\",\"E1022 Z794 |eoc| N183 M549\"\n",
    "FN_002,1,0,\"[]\",\"I10 E785 |eoc| K9289 O0903\"\n",
    "```\n",
    "\n",
    "**Possible causes**:\n",
    "1. **Target codes too specific**: Missing related codes (E1022 vs E119)\n",
    "2. **Generation parameters**: Temperature too low, not enough diversity\n",
    "3. **Model limitations**: Doesn't understand code relationships\n",
    "\n",
    "### Improvement Strategies\n",
    "\n",
    "#### For High False Positive Rate:\n",
    "```yaml\n",
    "target_word_evaluation:\n",
    "  target_codes: [\"E119\"]  # More specific codes\n",
    "  temperature: 0.7        # Less randomness\n",
    "  generations_per_prompt: 15  # More generations for stability\n",
    "```\n",
    "\n",
    "#### For High False Negative Rate:\n",
    "```yaml\n",
    "target_word_evaluation:\n",
    "  target_codes: [\"E119\", \"E1022\", \"E1040\", \"E1051\"]  # Include related codes\n",
    "  temperature: 0.9        # More diversity\n",
    "  max_new_tokens: 300     # Longer generations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Dataset Quality Assessment\n",
    "\n",
    "### Class Distribution Analysis\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"data_summary\": {\n",
    "    \"total_samples\": 5000,\n",
    "    \"positive_samples\": 1150,\n",
    "    \"negative_samples\": 3850,\n",
    "    \"positive_rate\": 0.23,\n",
    "    \"class_balance\": \"imbalanced\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Class balance interpretation**:\n",
    "- **Balanced (40-60%)**: Ideal for most metrics\n",
    "- **Mild imbalance (20-40% or 60-80%)**: Good, focus on F1-score\n",
    "- **Strong imbalance (<20% or >80%)**: Focus on precision/recall, ROC-AUC\n",
    "- **Severe imbalance (<10% or >90%)**: Consider resampling or different metrics\n",
    "\n",
    "### Data Quality Indicators\n",
    "\n",
    "#### Good Data Quality Signs:\n",
    "- âœ… **Consistent performance** across classifiers\n",
    "- âœ… **High cross-validation scores** (close to test scores)\n",
    "- âœ… **Reasonable embedding clusters** (similar claims have similar embeddings)\n",
    "- âœ… **Logical target code patterns** (clinically relevant codes appear together)\n",
    "\n",
    "#### Poor Data Quality Signs:\n",
    "- âŒ **Large CV/test performance gap** (overfitting due to data leakage)\n",
    "- âŒ **Random-level performance** (ROC-AUC â‰ˆ 0.5)\n",
    "- âŒ **Inconsistent target code results** (codes appear randomly)\n",
    "- âŒ **High variance across runs** (different random seeds give very different results)\n",
    "\n",
    "### Recommendations Based on Results\n",
    "\n",
    "#### Excellent Performance (>90% accuracy):\n",
    "```\n",
    "âœ… Model ready for production testing\n",
    "âœ… Consider expanding to more complex tasks\n",
    "âœ… Validate on external datasets\n",
    "```\n",
    "\n",
    "#### Good Performance (80-90% accuracy):\n",
    "```\n",
    "âœ… Model suitable for pilot deployment\n",
    "ğŸ”§ Fine-tune hyperparameters\n",
    "ğŸ”§ Consider ensemble methods\n",
    "```\n",
    "\n",
    "#### Fair Performance (70-80% accuracy):\n",
    "```\n",
    "ğŸ”§ Increase dataset size\n",
    "ğŸ”§ Improve label quality\n",
    "ğŸ”§ Try different target codes\n",
    "ğŸ”§ Consider model retraining\n",
    "```\n",
    "\n",
    "#### Poor Performance (<70% accuracy):\n",
    "```\n",
    "ğŸš¨ Review data quality\n",
    "ğŸš¨ Check model-data compatibility\n",
    "ğŸš¨ Verify API connectivity\n",
    "ğŸš¨ Consider different approach\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Actionable Insights\n",
    "\n",
    "### Production Deployment Checklist\n",
    "\n",
    "#### Before Production:\n",
    "- [ ] **Performance threshold met** (accuracy >80%, precision >75%)\n",
    "- [ ] **Statistical significance confirmed** (p < 0.05 in method comparison)\n",
    "- [ ] **Error analysis completed** (understand failure modes)\n",
    "- [ ] **External validation performed** (test on unseen data)\n",
    "- [ ] **Clinical review conducted** (domain expert validation)\n",
    "\n",
    "#### Production Monitoring:\n",
    "- [ ] **Performance tracking** (monitor accuracy over time)\n",
    "- [ ] **Data drift detection** (compare new data to training distribution)\n",
    "- [ ] **Error pattern monitoring** (watch for new failure modes)\n",
    "- [ ] **User feedback integration** (collect real-world performance data)\n",
    "\n",
    "### Research & Development Priorities\n",
    "\n",
    "#### High-Impact Improvements:\n",
    "1. **Data expansion**: More diverse, high-quality labeled data\n",
    "2. **Target code optimization**: Better selection based on clinical relevance\n",
    "3. **Model fine-tuning**: Adapt base model to your specific domain\n",
    "4. **Ensemble methods**: Combine multiple approaches for better performance\n",
    "\n",
    "#### Advanced Techniques:\n",
    "1. **Active learning**: Identify most informative samples for labeling\n",
    "2. **Multi-task learning**: Train on related tasks simultaneously\n",
    "3. **Domain adaptation**: Transfer knowledge from related domains\n",
    "4. **Uncertainty quantification**: Provide confidence estimates with predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— Next Steps\n",
    "\n",
    "### Immediate Actions:\n",
    "1. **Review your results** using the guidelines in this notebook\n",
    "2. **Identify best performing method** from `method_comparison.json`\n",
    "3. **Analyze errors** to understand failure modes\n",
    "4. **Plan improvements** based on performance gaps\n",
    "\n",
    "### Continue Learning:\n",
    "- **[06_Troubleshooting.ipynb](06_Troubleshooting.ipynb)** - Common issues and solutions\n",
    "- **[07_Advanced_Usage.ipynb](07_Advanced_Usage.ipynb)** - Production deployment and optimization\n",
    "\n",
    "### Quick Analysis Commands:\n",
    "\n",
    "```bash\n",
    "# Check overall results\n",
    "cat outputs/your_job/summary/pipeline_summary.json | jq '.best_results'\n",
    "\n",
    "# Find best method\n",
    "cat outputs/your_job/summary/method_comparison.json | jq '.recommendation'\n",
    "\n",
    "# Review detailed metrics\n",
    "ls outputs/your_job/metrics/*/metrics.json\n",
    "\n",
    "# Check for errors in logs\n",
    "grep -i error outputs/your_job/logs/pipeline.log\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}