# =============================================================================
# CLEAN DEFAULT CONFIGURATION FOR MGPT-EVAL PIPELINE
# =============================================================================
# This configuration uses ONLY valid fields from the PipelineConfig model.
# No duplicates, no non-existent sections, no aliases.
#
# Usage: python main.py run-all --config configs/default_config.yaml

# =============================================================================
# INPUT CONFIGURATION
# =============================================================================
input:
  dataset_path: "data/medical_claims.csv"  # ðŸ‘ˆ UPDATE: Your CSV file path
  split_ratio: 0.8                        # 80% train, 20% test
  
  # Optional: Use these instead of dataset_path for pre-split data
  # train_dataset_path: null
  # test_dataset_path: null
  
  # Optional: Pre-computed embeddings (skip embedding generation)
  # train_embeddings_path: null
  # test_embeddings_path: null
  
  # Optional: Pre-trained models (skip classification training)
  # model_paths: null
  # models_directory: null

# =============================================================================
# JOB CONFIGURATION
# =============================================================================
job:
  name: "mgpt_eval_default"
  output_dir: "outputs"
  random_seed: 42

# =============================================================================
# MODEL API CONFIGURATION
# =============================================================================
model_api:
  base_url: "http://localhost:8000"      # ðŸ‘ˆ UPDATE: Your model server URL
  timeout: 300
  max_retries: 3
  batch_size: 32
  
  endpoints:
    embeddings: "/embeddings"
    embeddings_batch: "/embeddings_batch"
    generate: "/generate"
    generate_batch: "/generate_batch"

# =============================================================================
# PIPELINE STAGES CONFIGURATION
# =============================================================================
pipeline_stages:
  embeddings: true              # Maps to generate_embeddings
  classification: true          # Maps to train_classifiers
  evaluation: true              # Maps to evaluate_models
  target_word_eval: false       # Maps to target_word_evaluation
  summary_report: true          # Maps to create_summary_report
  method_comparison: false      # Maps to compare_methods (requires target_word_eval=true)

# =============================================================================
# DATA PROCESSING CONFIGURATION
# =============================================================================
data_processing:
  random_seed: 42
  max_sequence_length: 512
  include_mcid: true
  output_format: "json"
  train_test_split: 0.8

# =============================================================================
# EMBEDDING GENERATION CONFIGURATION
# =============================================================================
embedding_generation:
  batch_size: 16
  save_interval: 100
  checkpoint_dir: "outputs/checkpoints"
  resume_from_checkpoint: true
  tokenizer_path: "/home/kosaraju/mgpt-serve/tokenizer"

# =============================================================================
# CLASSIFICATION CONFIGURATION
# =============================================================================
classification:
  models: ["logistic_regression", "svm", "random_forest"]
  
  cross_validation:
    n_folds: 5
    scoring: "roc_auc"
    n_jobs: -1
  
  hyperparameter_search:
    logistic_regression:
      C: [0.001, 0.01, 0.1, 1, 10, 100]
      penalty: ["l1", "l2"]
      solver: ["liblinear", "saga"]
    
    svm:
      C: [0.1, 1, 10]
      kernel: ["rbf", "linear"]
      gamma: ["scale", "auto"]
    
    random_forest:
      n_estimators: [100, 200, 300]
      max_depth: [10, 20, 30, null]
      min_samples_split: [2, 5, 10]

# =============================================================================
# EVALUATION CONFIGURATION
# =============================================================================
evaluation:
  metrics: ["accuracy", "precision", "recall", "f1_score", "roc_auc", "confusion_matrix"]
  
  visualization:
    generate_plots: true
    plot_formats: ["png", "pdf"]
    dpi: 300

# =============================================================================
# TARGET WORD EVALUATION CONFIGURATION
# =============================================================================
target_word_evaluation:
  enable: false                        # Set to true to enable this evaluation method
  target_codes: ["E119", "76642", "N6320", "K9289"]  # ðŸ‘ˆ UPDATE: Your medical codes
  # target_codes_file: null            # Alternative: load codes from file
  
  generations_per_prompt: 10
  max_new_tokens: 200
  temperature: 0.8
  top_k: 50
  search_method: "exact"

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
output:
  embeddings_dir: "outputs/embeddings"
  models_dir: "outputs/models"
  metrics_dir: "outputs/metrics"
  logs_dir: "outputs/logs"
  save_best_model_only: false
  model_format: "pickle"

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level: "INFO"
  console_level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "outputs/logs/pipeline.log"
  max_file_size: "10MB"
  backup_count: 5

# =============================================================================
# USAGE INSTRUCTIONS
# =============================================================================
# 1. ðŸ‘ˆ UPDATE input.dataset_path with your CSV file
# 2. ðŸ‘ˆ UPDATE model_api.base_url with your model server URL
# 3. ðŸ‘ˆ UPDATE target_word_evaluation.target_codes with your medical codes (if using)
# 4. Run: python main.py run-all --config configs/default_config.yaml
#
# This config uses only valid PipelineConfig model fields.
# The model handles field name aliases automatically.